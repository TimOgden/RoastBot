{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(1405982173)\n",
    "end_time = str(1595370973)\n",
    "url = 'http://api.pushshift.io/reddit/submission/search/?sort=desc&subreddit=RoastMe&limit=1000&after={}&before='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5c093f7affca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "r = requests.get(url)\n",
    "data = json.loads(r.text)\n",
    "data['data'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-994523ac874f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'author'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['data'][0]['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-a3802da6abf1>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm(range(start, end, 60*60*24*2)): #get results every 2 days\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97422a4e9baf45bbacfe36323956b78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-01-01 17:36:13\n",
      "2014-07-20 18:36:13\n",
      "2015-02-05 17:36:13\n",
      "2015-08-24 18:36:13\n",
      "2016-03-11 17:36:13\n",
      "2016-09-27 18:36:13\n",
      "2017-04-15 18:36:13\n",
      "2017-11-01 18:36:13\n",
      "2018-05-20 18:36:13\n",
      "2018-12-06 17:36:13\n",
      "2019-06-24 18:36:13\n",
      "2020-01-10 17:36:13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start=1388615773\n",
    "end=1595370973\n",
    "previous_epoch = start\n",
    "all_posts = {}\n",
    "c = 0\n",
    "for epoch in tqdm(range(start, end, 60*60*24*1)): #get results every 2 days\n",
    "    if c%100==0:\n",
    "        print(datetime.fromtimestamp(epoch))\n",
    "    r = requests.get(url.format(previous_epoch) + str(epoch))\n",
    "    data = json.loads(r.text)\n",
    "    for entry in data['data']:\n",
    "        if entry['score'] > 20 and entry['num_comments'] > 2 and entry['id'] not in all_posts:\n",
    "            all_posts[entry['id']] = entry['url']\n",
    "    time.sleep(1)\n",
    "    previous_epoch = epoch\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4761"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(all_posts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3c082j', 'http://imgur.com/1qAyCSA')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = list(all_posts.keys())[5]\n",
    "(key, all_posts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"A lot of the comments are insinuating that you're gay, but I doubt it. That would be far too unusual. You're about as interesting as a toast sandwich. I don't think you've ever had an original thought. You've done average-to-good in school and you'll continue to do average-to-good in life. You'll settle down in your early 30s when you stumble across another equally vapid female who's begun to get those desperate thoughts that she might never marry or have children. You look as if someone took a boring as fuck, personality-devoid, mindless cretin, covered them in glue and threw them into Urban Outfitters in the vain hope it would make them look the slightest bit intriguing. It hasn't worked. You probably won't endure that much hardship in life but you'll go to the grave knowing that no one was ever truly *interested* in you and that, in the grand scheme of things, you have made no impact on anything whatsoever. \",\n",
       "  824],\n",
       " [\"You're like the IRL disappointing Tinder match for someone that thought they were going to hook up with the Brawny guy.  \",\n",
       "  364],\n",
       " ['You look like a default Sims character.', 224],\n",
       " ['You look like a Mormon Christopher Hemsworth lumberjack who moonlights as a gloryhole jockey.  ',\n",
       "  182],\n",
       " ['Does your husband know you post here?', 162]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_root_comments(_id, score_threshold=10, top_n=5):\n",
    "    comments = []\n",
    "    url = 'https://api.pushshift.io/reddit/comment/search/?sort_type=score&sort=desc&link_id={}&subreddit=RoastMe&limit=1000'.format(_id)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    for entry in data['data']:\n",
    "        if entry['parent_id'][:3] == 't3_': # making sure it's a root comment\n",
    "            if entry['score'] > score_threshold:\n",
    "                comments.append([entry['body'],entry['score']])\n",
    "    if len(comments)>5:\n",
    "        return comments[:5]\n",
    "    return comments\n",
    "get_root_comments('4re2dn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_img(filename, url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open('./faces/{}.png'.format(filename), 'wb') as out_file:\n",
    "        shutil.copyfileobj(response.raw, out_file)\n",
    "    del response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-115-1bd1607c41b4>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for c, key in tqdm(enumerate(list(all_posts.keys()))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fafff656bc41caa5a652eff4f64713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for c, key in tqdm(enumerate(list(all_posts.keys()))):\n",
    "    download_img(key, all_posts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'Load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-145788b95124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;31m# Crop all jpegs in a folder. Note: the code uses glob which follows unix shell rules.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;31m# Use the boxScale to scale the cropping area. 1=opencv box, 2=2x the width and height\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[0mfaceCrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'faces/*.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxScale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-145788b95124>\u001b[0m in \u001b[0;36mfaceCrop\u001b[1;34m(imagePattern, boxScale)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m#   haarcascade_frontalface_default.xml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;31m#   haarcascade_profileface.xml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mfaceCascade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'haarcascade_frontalface_alt.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mimgList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'Load'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sources:\n",
    "http://opencv.willowgarage.com/documentation/python/cookbook.html\n",
    "http://www.lucaamore.com/?p=638\n",
    "'''\n",
    "\n",
    "#Python 2.7.2\n",
    "#Opencv 2.4.2\n",
    "#PIL 1.1.7\n",
    "\n",
    "import cv2 #Opencv\n",
    "import PIL.Image #Image from PIL\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def DetectFace(image, faceCascade, returnImage=False):\n",
    "    # This function takes a grey scale cv image and finds\n",
    "    # the patterns defined in the haarcascade function\n",
    "    # modified from: http://www.lucaamore.com/?p=638\n",
    "\n",
    "    #variables    \n",
    "    min_size = (20,20)\n",
    "    haar_scale = 1.1\n",
    "    min_neighbors = 3\n",
    "    haar_flags = 0\n",
    "\n",
    "    # Equalize the histogram\n",
    "    cv2.EqualizeHist(image, image)\n",
    "\n",
    "    # Detect the faces\n",
    "    faces = cv2.HaarDetectObjects(\n",
    "            image, faceCascade, cv2.CreateMemStorage(0),\n",
    "            haar_scale, min_neighbors, haar_flags, min_size\n",
    "        )\n",
    "\n",
    "    # If faces are found\n",
    "    if faces and returnImage:\n",
    "        for ((x, y, w, h), n) in faces:\n",
    "            # Convert bounding box to two CvPoints\n",
    "            pt1 = (int(x), int(y))\n",
    "            pt2 = (int(x + w), int(y + h))\n",
    "            cv2.Rectangle(image, pt1, pt2, cv2.RGB(255, 0, 0), 5, 8, 0)\n",
    "\n",
    "    if returnImage:\n",
    "        return image\n",
    "    else:\n",
    "        return faces\n",
    "\n",
    "def pil2cvGrey(pil_im):\n",
    "    # Convert a PIL image to a greyscale cv image\n",
    "    # from: http://pythonpath.wordpress.com/2012/05/08/pil-to-opencv-image/\n",
    "    pil_im = pil_im.convert('L')\n",
    "    cv_im = cv.CreateImageHeader(pil_im.size, cv.IPL_DEPTH_8U, 1)\n",
    "    cv2.SetData(cv_im, pil_im.tostring(), pil_im.size[0]  )\n",
    "    return cv_im\n",
    "\n",
    "def cv2pil(cv_im):\n",
    "    # Convert the cv image to a PIL image\n",
    "    return Image.fromstring(\"L\", cv2.GetSize(cv_im), cv_im.tostring())\n",
    "\n",
    "def imgCrop(image, cropBox, boxScale=1):\n",
    "    # Crop a PIL image with the provided box [x(left), y(upper), w(width), h(height)]\n",
    "\n",
    "    # Calculate scale factors\n",
    "    xDelta=max(cropBox[2]*(boxScale-1),0)\n",
    "    yDelta=max(cropBox[3]*(boxScale-1),0)\n",
    "\n",
    "    # Convert cv box to PIL box [left, upper, right, lower]\n",
    "    PIL_box=[cropBox[0]-xDelta, cropBox[1]-yDelta, cropBox[0]+cropBox[2]+xDelta, cropBox[1]+cropBox[3]+yDelta]\n",
    "\n",
    "    return image.crop(PIL_box)\n",
    "\n",
    "def faceCrop(imagePattern,boxScale=1):\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    faceCascade = cv2.Load('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    imgList=glob.glob(imagePattern)\n",
    "    if len(imgList)<=0:\n",
    "        print('No Images Found')\n",
    "        return\n",
    "\n",
    "    for img in imgList:\n",
    "        pil_im=Image.open(img)\n",
    "        cv_im=pil2cvGrey(pil_im)\n",
    "        faces=DetectFace(cv_im,faceCascade)\n",
    "        if faces:\n",
    "            n=1\n",
    "            for face in faces:\n",
    "                croppedImage=imgCrop(pil_im, face[0],boxScale=boxScale)\n",
    "                fname,ext=os.path.splitext(img)\n",
    "                croppedImage.save(fname+'_crop'+str(n)+ext)\n",
    "                n+=1\n",
    "        else:\n",
    "            print('No faces found:', img)\n",
    "\n",
    "def test(imageFilePath):\n",
    "    pil_im=Image.open(imageFilePath)\n",
    "    cv_im=pil2cvGrey(pil_im)\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    faceCascade = cv2.Load('haarcascade_frontalface_alt.xml')\n",
    "    face_im=DetectFace(cv_im,faceCascade, returnImage=True)\n",
    "    img=cv2pil(face_im)\n",
    "    img.show()\n",
    "    img.save('test.png')\n",
    "\n",
    "\n",
    "# Test the algorithm on an image\n",
    "#test('testPics/faces.jpg')\n",
    "\n",
    "# Crop all jpegs in a folder. Note: the code uses glob which follows unix shell rules.\n",
    "# Use the boxScale to scale the cropping area. 1=opencv box, 2=2x the width and height\n",
    "faceCrop('faces/*.png',boxScale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
